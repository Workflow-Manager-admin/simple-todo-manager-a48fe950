{"is_source_file": false, "format": "", "description": "", "external_files": [], "external_methods": [], "published": [], "classes": [], "methods": [], "calls": [], "search-terms": ["robots.txt", "web crawlers", "robots exclusion protocol"], "state": 2, "file_id": 13, "knowledge_revision": 29, "git_revision": "55e601afeb8730db8f387d865d2ea2e94850b46b", "hash": "fa1ded1ed7c11438a9b0385b1e112850", "format-version": 4, "code-base-name": "todo_frontend", "filename": "todo_frontend/public/robots.txt", "revision_history": [{"29": "55e601afeb8730db8f387d865d2ea2e94850b46b"}]}